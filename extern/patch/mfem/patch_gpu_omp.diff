diff --git a/general/forall.hpp b/general/forall.hpp
index 35376c7c8e..92f7f12004 100644
--- a/general/forall.hpp
+++ b/general/forall.hpp
@@ -23,9 +23,6 @@
 #include <_hypre_utilities.h>
 #endif
 
-#include "array.hpp"
-#include "reducers.hpp"
-
 namespace mfem
 {
 
@@ -849,159 +846,6 @@ inline MemoryClass GetHypreForallMemoryClass()
 
 #endif // MFEM_USE_MPI
 
-namespace internal
-{
-/**
- @brief Device portion of a reduction over a 1D sequence [0, N)
- @tparam B Reduction body. Must be callable with the signature void(int i, value_type&
- v), where i is the index to evaluate and v is the value to update.
- @tparam R Reducer capable of combining values of type value_type. See reducers.hpp for
- pre-defined reducers.
- */
-template<class B, class R> struct reduction_kernel
-{
-   /// value type body and reducer operate on.
-   using value_type = typename R::value_type;
-   /// workspace for the intermediate reduction results
-   mutable value_type *work;
-   B body;
-   R reducer;
-   /// Length of sequence to reduce over.
-   int N;
-   /// How many items is each thread responsible for during the serial phase
-   int items_per_thread;
-
-   constexpr static MFEM_HOST_DEVICE int max_blocksize() { return 256; }
-
-   /// helper for computing the reduction block size
-   static int block_log2(unsigned N)
-   {
-#if defined(__GNUC__) or defined(__clang__)
-      return N ? (sizeof(unsigned) * 8 - __builtin_clz(N)) : 0;
-#elif defined(_MSC_VER)
-      return sizeof(unsigned) * 8 - __lzclz(N);
-#else
-      int res = 0;
-      while (N)
-      {
-         N >>= 1;
-         ++res;
-      }
-      return res;
-#endif
-   }
-
-   MFEM_HOST_DEVICE void operator()(int work_idx) const
-   {
-      MFEM_SHARED value_type buffer[max_blocksize()];
-      reducer.SetInitialValue(buffer[MFEM_THREAD_ID(x)]);
-      // serial part
-      for (int idx = 0; idx < items_per_thread; ++idx)
-      {
-         int i = MFEM_THREAD_ID(x) +
-                 (idx + work_idx * items_per_thread) * MFEM_THREAD_SIZE(x);
-         if (i < N)
-         {
-            body(i, buffer[MFEM_THREAD_ID(x)]);
-         }
-         else
-         {
-            break;
-         }
-      }
-      // binary tree reduction
-      for (int i = (MFEM_THREAD_SIZE(x) >> 1); i > 0; i >>= 1)
-      {
-         MFEM_SYNC_THREAD;
-         if (MFEM_THREAD_ID(x) < i)
-         {
-            reducer.Join(buffer[MFEM_THREAD_ID(x)], buffer[MFEM_THREAD_ID(x) + i]);
-         }
-      }
-      if (MFEM_THREAD_ID(x) == 0)
-      {
-         work[work_idx] = buffer[0];
-      }
-   }
-};
-}
-
-/**
- @brief Performs a 1D reduction on the range [0,N).
- @a res initial value and where the result will be written.
- @a body reduction function body.
- @a reducer helper for joining two reduced values.
- @a use_dev true to perform the reduction on the device, if possible.
- @a workspace temporary workspace used for device reductions. May be resized to
- a larger capacity as needed. Preferably should have MemoryType::MANAGED or
- MemoryType::HOST_PINNED. TODO: replace with internal temporary workspace
- vectors once that's added to the memory manager.
- @tparam T value_type to operate on
- */
-template <class T, class B, class R>
-void reduce(int N, T &res, B &&body, const R &reducer, bool use_dev,
-            Array<T> &workspace)
-{
-   if (N == 0)
-   {
-      return;
-   }
-
-#if defined(MFEM_USE_HIP) || defined(MFEM_USE_CUDA)
-   if (use_dev &&
-       mfem::Device::Allows(Backend::CUDA | Backend::HIP | Backend::RAJA_CUDA |
-                            Backend::RAJA_HIP))
-   {
-      using red_type = internal::reduction_kernel<typename std::decay<B>::type,
-            typename std::decay<R>::type>;
-      // max block size is 256, but can be smaller
-      int block_size = std::min<int>(red_type::max_blocksize(),
-                                     1ll << red_type::block_log2(N));
-
-      int num_mp = Device::NumMultiprocessors(Device::GetId());
-#if defined(MFEM_USE_CUDA)
-      // good value of mp_sat found experimentally on Lassen
-      constexpr int mp_sat = 8;
-#elif defined(MFEM_USE_HIP)
-      // good value of mp_sat found experimentally on Tuolumne
-      constexpr int mp_sat = 4;
-#else
-      num_mp = 1;
-      constexpr int mp_sat = 1;
-#endif
-      // determine how many items each thread should sum during the serial
-      // portion
-      int nblocks = std::min(mp_sat * num_mp, (N + block_size - 1) / block_size);
-      int items_per_thread =
-         (N + block_size * nblocks - 1) / (block_size * nblocks);
-
-      red_type red{nullptr, std::forward<B>(body), reducer, N, items_per_thread};
-      // allocate res to fit block_size entries
-      auto mt = workspace.GetMemory().GetMemoryType();
-      if (mt != MemoryType::HOST_PINNED && mt != MemoryType::MANAGED)
-      {
-         mt = MemoryType::HOST_PINNED;
-      }
-      workspace.SetSize(nblocks, mt);
-      auto work = workspace.HostWrite();
-      red.work = work;
-      forall_2D(nblocks, block_size, 1, std::move(red));
-      // wait for results
-      MFEM_DEVICE_SYNC;
-      for (int i = 0; i < nblocks; ++i)
-      {
-         reducer.Join(res, work[i]);
-      }
-      return;
-   }
-#endif
-
-   for (int i = 0; i < N; ++i)
-   {
-      body(i, res);
-   }
-}
-
 } // namespace mfem
 
 #endif // MFEM_FORALL_HPP
diff --git a/general/reducers.hpp b/general/reducers.hpp
index 2b77fcbf1a..dde3bd4e5d 100644
--- a/general/reducers.hpp
+++ b/general/reducers.hpp
@@ -12,11 +12,10 @@
 #ifndef MFEM_REDUCERS_HPP
 #define MFEM_REDUCERS_HPP
 
+#include "array.hpp"
 #include "forall.hpp"
 
-#include <climits>
 #include <cmath>
-#include <cstdint>
 #include <limits>
 #include <type_traits>
 
@@ -439,6 +438,160 @@ template <class I> struct ArgMinMaxReducer<double, I>
    }
 };
 
-} // namespace mfem
+namespace internal
+{
+
+/**
+ @brief Device portion of a reduction over a 1D sequence [0, N)
+ @tparam B Reduction body. Must be callable with the signature void(int i, value_type&
+ v), where i is the index to evaluate and v is the value to update.
+ @tparam R Reducer capable of combining values of type value_type. See reducers.hpp for
+ pre-defined reducers.
+ */
+template<class B, class R> struct reduction_kernel
+{
+   /// value type body and reducer operate on.
+   using value_type = typename R::value_type;
+   /// workspace for the intermediate reduction results
+   mutable value_type *work;
+   B body;
+   R reducer;
+   /// Length of sequence to reduce over.
+   int N;
+   /// How many items is each thread responsible for during the serial phase
+   int items_per_thread;
+
+   constexpr static MFEM_HOST_DEVICE int max_blocksize() { return 256; }
+
+   /// helper for computing the reduction block size
+   static int block_log2(unsigned N)
+   {
+#if defined(__GNUC__) or defined(__clang__)
+      return N ? (sizeof(unsigned) * 8 - __builtin_clz(N)) : 0;
+#elif defined(_MSC_VER)
+      return sizeof(unsigned) * 8 - __lzclz(N);
+#else
+      int res = 0;
+      while (N)
+      {
+         N >>= 1;
+         ++res;
+      }
+      return res;
+#endif
+   }
 
+   MFEM_HOST_DEVICE void operator()(int work_idx) const
+   {
+      MFEM_SHARED value_type buffer[max_blocksize()];
+      reducer.SetInitialValue(buffer[MFEM_THREAD_ID(x)]);
+      // serial part
+      for (int idx = 0; idx < items_per_thread; ++idx)
+      {
+         int i = MFEM_THREAD_ID(x) +
+                 (idx + work_idx * items_per_thread) * MFEM_THREAD_SIZE(x);
+         if (i < N)
+         {
+            body(i, buffer[MFEM_THREAD_ID(x)]);
+         }
+         else
+         {
+            break;
+         }
+      }
+      // binary tree reduction
+      for (int i = (MFEM_THREAD_SIZE(x) >> 1); i > 0; i >>= 1)
+      {
+         MFEM_SYNC_THREAD;
+         if (MFEM_THREAD_ID(x) < i)
+         {
+            reducer.Join(buffer[MFEM_THREAD_ID(x)], buffer[MFEM_THREAD_ID(x) + i]);
+         }
+      }
+      if (MFEM_THREAD_ID(x) == 0)
+      {
+         work[work_idx] = buffer[0];
+      }
+   }
+};
+}
+
+/**
+ @brief Performs a 1D reduction on the range [0,N).
+ @a res initial value and where the result will be written.
+ @a body reduction function body.
+ @a reducer helper for joining two reduced values.
+ @a use_dev true to perform the reduction on the device, if possible.
+ @a workspace temporary workspace used for device reductions. May be resized to
+ a larger capacity as needed. Preferably should have MemoryType::MANAGED or
+ MemoryType::HOST_PINNED. TODO: replace with internal temporary workspace
+ vectors once that's added to the memory manager.
+ @tparam T value_type to operate on
+ */
+template <class T, class B, class R>
+void reduce(int N, T &res, B &&body, const R &reducer, bool use_dev,
+            Array<T> &workspace)
+{
+   if (N == 0)
+   {
+      return;
+   }
+
+#if defined(MFEM_USE_HIP) || defined(MFEM_USE_CUDA)
+   if (use_dev &&
+       mfem::Device::Allows(Backend::CUDA | Backend::HIP | Backend::RAJA_CUDA |
+                            Backend::RAJA_HIP))
+   {
+      using red_type = internal::reduction_kernel<typename std::decay<B>::type,
+            typename std::decay<R>::type>;
+      // max block size is 256, but can be smaller
+      int block_size = std::min<int>(red_type::max_blocksize(),
+                                     1ll << red_type::block_log2(N));
+
+      int num_mp = Device::NumMultiprocessors(Device::GetId());
+#if defined(MFEM_USE_CUDA)
+      // good value of mp_sat found experimentally on Lassen
+      constexpr int mp_sat = 8;
+#elif defined(MFEM_USE_HIP)
+      // good value of mp_sat found experimentally on Tuolumne
+      constexpr int mp_sat = 4;
+#else
+      num_mp = 1;
+      constexpr int mp_sat = 1;
 #endif
+      // determine how many items each thread should sum during the serial
+      // portion
+      int nblocks = std::min(mp_sat * num_mp, (N + block_size - 1) / block_size);
+      int items_per_thread =
+         (N + block_size * nblocks - 1) / (block_size * nblocks);
+
+      red_type red{nullptr, std::forward<B>(body), reducer, N, items_per_thread};
+      // allocate res to fit block_size entries
+      auto mt = workspace.GetMemory().GetMemoryType();
+      if (mt != MemoryType::HOST_PINNED && mt != MemoryType::MANAGED)
+      {
+         mt = MemoryType::HOST_PINNED;
+      }
+      workspace.SetSize(nblocks, mt);
+      auto work = workspace.HostWrite();
+      red.work = work;
+      forall_2D(nblocks, block_size, 1, std::move(red));
+      // wait for results
+      MFEM_DEVICE_SYNC;
+      for (int i = 0; i < nblocks; ++i)
+      {
+         reducer.Join(res, work[i]);
+      }
+      return;
+   }
+#endif
+
+   for (int i = 0; i < N; ++i)
+   {
+      body(i, res);
+   }
+}
+
+} // namespace mfem
+
+#endif // MFEM_REDUCERS_HPP
diff --git a/linalg/vector.cpp b/linalg/vector.cpp
index 87b063c025..ca44723585 100644
--- a/linalg/vector.cpp
+++ b/linalg/vector.cpp
@@ -11,19 +11,18 @@
 
 // Implementation of data type vector
 
-#include "kernels.hpp"
-#include "vector.hpp"
 #include "../general/forall.hpp"
+#include "../general/reducers.hpp"
+#include "../general/hash.hpp"
+#include "vector.hpp"
 
 #ifdef MFEM_USE_OPENMP
 #include <omp.h>
 #endif
 
 #include <iostream>
-#include <iomanip>
 #include <cmath>
 #include <ctime>
-#include <limits>
 
 namespace mfem
 {
@@ -1070,161 +1069,179 @@ real_t Vector::operator*(const Vector &v) const
    MFEM_ASSERT(size == v.size, "incompatible Vectors!");
    if (size == 0) { return 0.0; }
 
-   const bool use_dev = UseDevice() || v.UseDevice();
+   // If OCCA is enabled, it handles all selected backends
+#ifdef MFEM_USE_OCCA
+   if (DeviceCanUseOcca())
+   {
+      return occa::linalg::dot<real_t, real_t, real_t>(
+                OccaMemoryRead(data, size), OccaMemoryRead(v.data, size));
+   }
+#endif
 
-   auto m_data = Read(use_dev);
-   auto v_data = v.Read(use_dev);
+   const bool use_dev = UseDevice() || v.UseDevice();
+   const auto m_data = Read(use_dev), v_data = v.Read(use_dev);
 
-   if (use_dev)
+   const auto compute_dot = [&]()
    {
-      // special path for OCCA and OpenMP
-#ifdef MFEM_USE_OCCA
-      if (DeviceCanUseOcca())
+      real_t res = 0;
+      reduce(size, res, [=] MFEM_HOST_DEVICE (int i, real_t &r)
       {
-         return occa::linalg::dot<real_t, real_t, real_t>(
-                   OccaMemoryRead(data, size), OccaMemoryRead(v.data, size));
-      }
-#endif
+         r += m_data[i] * v_data[i];
+      },
+      SumReducer<real_t> {}, use_dev, vector_workspace());
+      return res;
+   };
+
+   // Device backends have top priority
+   if (Device::Allows(Backend::DEVICE_MASK)) { return compute_dot(); }
 
+   // Special path for OpenMP
 #ifdef MFEM_USE_OPENMP
-      if (Device::Allows(Backend::OMP_MASK))
-      {
+   if (Device::Allows(Backend::OMP_MASK))
+   {
+      // By default, use a deterministic way of computing the dot product
 #define MFEM_USE_OPENMP_DETERMINISTIC_DOT
 #ifdef MFEM_USE_OPENMP_DETERMINISTIC_DOT
-         // By default, use a deterministic way of computing the dot product
-         static Vector th_dot;
-         #pragma omp parallel
+      static Vector th_dot;
+      #pragma omp parallel
+      {
+         const int nt = omp_get_num_threads();
+         #pragma omp master
+         th_dot.SetSize(nt);
+         const int tid = omp_get_thread_num();
+         const int stride = (size + nt - 1) / nt;
+         const int start = tid * stride;
+         const int stop = std::min(start + stride, size);
+         real_t my_dot = 0.0;
+         for (int i = start; i < stop; i++)
          {
-            const int nt = omp_get_num_threads();
-            #pragma omp master
-            th_dot.SetSize(nt);
-            const int tid = omp_get_thread_num();
-            const int stride = (size + nt - 1) / nt;
-            const int start = tid * stride;
-            const int stop = std::min(start + stride, size);
-            real_t my_dot = 0.0;
-            for (int i = start; i < stop; i++)
-            {
-               my_dot += m_data[i] * v_data[i];
-            }
-            #pragma omp barrier
-            th_dot(tid) = my_dot;
+            my_dot += m_data[i] * v_data[i];
          }
-         return th_dot.Sum();
+         #pragma omp barrier
+         th_dot(tid) = my_dot;
+      }
+      return th_dot.Sum();
 #else
-         // The standard way of computing the dot product is non-deterministic
-         real_t prod = 0.0;
-         #pragma omp parallel for reduction(+ : prod)
-         for (int i = 0; i < size; i++)
-         {
-            prod += m_data[i] * v_data[i];
-         }
-         return prod;
-#endif // MFEM_USE_OPENMP_DETERMINISTIC_DOT
+      // The standard way of computing the dot product is non-deterministic
+      real_t prod = 0.0;
+      #pragma omp parallel for reduction(+ : prod)
+      for (int i = 0; i < size; i++)
+      {
+         prod += m_data[i] * v_data[i];
       }
-#endif // MFEM_USE_OPENMP
+      return prod;
+#endif // MFEM_USE_OPENMP_DETERMINISTIC_DOT
    }
+#endif // MFEM_USE_OPENMP
 
-   // normal path for everything else (cuda, hip, debug, cpu)
-   real_t res = 0;
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r += m_data[i] * v_data[i]; },
-   SumReducer<real_t> {}, use_dev, vector_workspace());
-   return res;
+   // All other CPU backends
+   return compute_dot();
 }
 
 real_t Vector::Min() const
 {
    if (size == 0) { return infinity(); }
 
-   const bool use_dev = UseDevice();
-   auto m_data = Read(use_dev);
-
-   if (use_dev)
+#ifdef MFEM_USE_OCCA
+   if (DeviceCanUseOcca())
    {
-      // special case for OCCA and OpenMP
+      return occa::linalg::min<real_t,real_t>(OccaMemoryRead(data, size));
+   }
+#endif
 
-#ifdef MFEM_USE_OCCA
-      if (DeviceCanUseOcca())
+   const auto use_dev = UseDevice();
+   const auto m_data = Read(use_dev);
+
+   const auto compute_min = [&]()
+   {
+      real_t res = infinity();
+      reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
       {
-         return occa::linalg::min<real_t,real_t>(OccaMemoryRead(data, size));
-      }
-#endif
+         r = fmin(r, m_data[i]);
+      },
+      MinReducer<real_t> {}, use_dev, vector_workspace());
+      return res;
+   };
+
+   // Device backends have top priority
+   if (Device::Allows(Backend::DEVICE_MASK)) { return compute_min(); }
 
+   // Special path for OpenMP
 #ifdef MFEM_USE_OPENMP
-      if (Device::Allows(Backend::OMP_MASK))
+   if (Device::Allows(Backend::OMP_MASK))
+   {
+      real_t minimum = m_data[0];
+      #pragma omp parallel for reduction(min:minimum)
+      for (int i = 0; i < size; i++)
       {
-         real_t minimum = m_data[0];
-         #pragma omp parallel for reduction(min:minimum)
-         for (int i = 0; i < size; i++)
-         {
-            minimum = std::min(minimum, m_data[i]);
-         }
-         return minimum;
+         minimum = std::min(minimum, m_data[i]);
       }
-#endif
+      return minimum;
    }
+#endif
 
-   // normal path for everything else (cuda, hip, debug, cpu)
-   real_t res = infinity();
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r = fmin(r, m_data[i]); },
-   MinReducer<real_t> {}, use_dev, vector_workspace());
-   return res;
+   // All other CPU backends
+   return compute_min();
 }
 
 real_t Vector::Max() const
 {
    if (size == 0) { return -infinity(); }
 
-   const bool use_dev = UseDevice();
-   auto m_data = Read(use_dev);
+#ifdef MFEM_USE_OCCA
+   if (DeviceCanUseOcca())
+   {
+      return occa::linalg::max<real_t, real_t>(OccaMemoryRead(data, size));
+   }
+#endif
+
+   const auto use_dev = UseDevice();
+   const auto m_data = Read(use_dev);
 
-   if (use_dev)
+   const auto compute_max = [&]()
    {
-      // special cases where OCCA or OenMP are used
-#ifdef MFEM_USE_OCCA
-      if (DeviceCanUseOcca())
+      real_t res = -infinity();
+      reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
       {
-         return occa::linalg::max<real_t, real_t>(OccaMemoryRead(data, size));
-      }
-#endif
+         r = fmax(r, m_data[i]);
+      },
+      MaxReducer<real_t> {}, use_dev, vector_workspace());
+      return res;
+   };
+
+   // Device backends have top priority
+   if (Device::Allows(Backend::DEVICE_MASK)) { return compute_max(); }
 
+   // Special path for OpenMP
 #ifdef MFEM_USE_OPENMP
-      if (Device::Allows(Backend::OMP_MASK))
+   if (Device::Allows(Backend::OMP_MASK))
+   {
+      real_t maximum = m_data[0];
+      #pragma omp parallel for reduction(max : maximum)
+      for (int i = 0; i < size; i++)
       {
-         real_t maximum = m_data[0];
-         #pragma omp parallel for reduction(max : maximum)
-         for (int i = 0; i < size; i++)
-         {
-            maximum = fmax(maximum, m_data[i]);
-         }
-         return maximum;
+         maximum = fmax(maximum, m_data[i]);
       }
-#endif
+      return maximum;
    }
+#endif
 
-   // normal path for everything else (cuda, hip, debug, cpu)
-   real_t res = -infinity();
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r = fmax(r, m_data[i]); },
-   MaxReducer<real_t> {}, use_dev, vector_workspace());
-   return res;
+   // All other CPU backends
+   return compute_max();
 }
 
 real_t Vector::Sum() const
 {
    if (size == 0) { return 0.0; }
 
-   auto m_data = Read(UseDevice());
+   const auto m_data = Read(UseDevice());
    real_t res = 0;
-   reduce(
-   size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r) { r += m_data[i]; },
+   reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
+   {
+      r += m_data[i];
+   },
    SumReducer<real_t> {}, UseDevice(), vector_workspace());
    return res;
 }
 
-}
+} // namespace mfem
diff --git a/tests/unit/general/test_reduction.cpp b/tests/unit/general/test_reduction.cpp
index 13b9077381..ad12cdb62d 100644
--- a/tests/unit/general/test_reduction.cpp
+++ b/tests/unit/general/test_reduction.cpp
@@ -9,15 +9,14 @@
 // terms of the BSD-3 license. We welcome feedback and contributions, see file
 // CONTRIBUTING.md for details.
 
-#include "mfem.hpp"
-
-// must be included after mfem.hpp
-#include "general/forall.hpp"
+#include <algorithm>
+#include <limits>
 
+#include "mfem.hpp"
 #include "unit_tests.hpp"
 
-#include <algorithm>
-#include <limits>
+// must be included after mfem.hpp
+#include "general/reducers.hpp"
 
 using namespace mfem;
 
