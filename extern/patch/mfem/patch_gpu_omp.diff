diff --git a/general/forall.hpp b/general/forall.hpp
index 5cc1a6b62d..164582d80b 100644
--- a/general/forall.hpp
+++ b/general/forall.hpp
@@ -23,9 +23,6 @@
 #include <_hypre_utilities.h>
 #endif

-#include "array.hpp"
-#include "reducers.hpp"
-
 namespace mfem
 {

@@ -853,159 +850,6 @@ inline MemoryClass GetHypreForallMemoryClass()

 #endif // MFEM_USE_MPI

-namespace internal
-{
-/**
- @brief Device portion of a reduction over a 1D sequence [0, N)
- @tparam B Reduction body. Must be callable with the signature void(int i, value_type&
- v), where i is the index to evaluate and v is the value to update.
- @tparam R Reducer capable of combining values of type value_type. See reducers.hpp for
- pre-defined reducers.
- */
-template<class B, class R> struct reduction_kernel
-{
-   /// value type body and reducer operate on.
-   using value_type = typename R::value_type;
-   /// workspace for the intermediate reduction results
-   mutable value_type *work;
-   B body;
-   R reducer;
-   /// Length of sequence to reduce over.
-   int N;
-   /// How many items is each thread responsible for during the serial phase
-   int items_per_thread;
-
-   constexpr static MFEM_HOST_DEVICE int max_blocksize() { return 256; }
-
-   /// helper for computing the reduction block size
-   static int block_log2(unsigned N)
-   {
-#if defined(__GNUC__) || defined(__clang__)
-      return N ? (sizeof(unsigned) * 8 - __builtin_clz(N)) : 0;
-#elif defined(_MSC_VER)
-      return sizeof(unsigned) * 8 - __lzclz(N);
-#else
-      int res = 0;
-      while (N)
-      {
-         N >>= 1;
-         ++res;
-      }
-      return res;
-#endif
-   }
-
-   MFEM_HOST_DEVICE void operator()(int work_idx) const
-   {
-      MFEM_SHARED value_type buffer[max_blocksize()];
-      reducer.SetInitialValue(buffer[MFEM_THREAD_ID(x)]);
-      // serial part
-      for (int idx = 0; idx < items_per_thread; ++idx)
-      {
-         int i = MFEM_THREAD_ID(x) +
-                 (idx + work_idx * items_per_thread) * MFEM_THREAD_SIZE(x);
-         if (i < N)
-         {
-            body(i, buffer[MFEM_THREAD_ID(x)]);
-         }
-         else
-         {
-            break;
-         }
-      }
-      // binary tree reduction
-      for (int i = (MFEM_THREAD_SIZE(x) >> 1); i > 0; i >>= 1)
-      {
-         MFEM_SYNC_THREAD;
-         if (MFEM_THREAD_ID(x) < i)
-         {
-            reducer.Join(buffer[MFEM_THREAD_ID(x)], buffer[MFEM_THREAD_ID(x) + i]);
-         }
-      }
-      if (MFEM_THREAD_ID(x) == 0)
-      {
-         work[work_idx] = buffer[0];
-      }
-   }
-};
-}
-
-/**
- @brief Performs a 1D reduction on the range [0,N).
- @a res initial value and where the result will be written.
- @a body reduction function body.
- @a reducer helper for joining two reduced values.
- @a use_dev true to perform the reduction on the device, if possible.
- @a workspace temporary workspace used for device reductions. May be resized to
- a larger capacity as needed. Preferably should have MemoryType::MANAGED or
- MemoryType::HOST_PINNED. TODO: replace with internal temporary workspace
- vectors once that's added to the memory manager.
- @tparam T value_type to operate on
- */
-template <class T, class B, class R>
-void reduce(int N, T &res, B &&body, const R &reducer, bool use_dev,
-            Array<T> &workspace)
-{
-   if (N == 0)
-   {
-      return;
-   }
-
-#if defined(MFEM_USE_HIP) || defined(MFEM_USE_CUDA)
-   if (use_dev &&
-       mfem::Device::Allows(Backend::CUDA | Backend::HIP | Backend::RAJA_CUDA |
-                            Backend::RAJA_HIP))
-   {
-      using red_type = internal::reduction_kernel<typename std::decay<B>::type,
-            typename std::decay<R>::type>;
-      // max block size is 256, but can be smaller
-      int block_size = std::min<int>(red_type::max_blocksize(),
-                                     1ll << red_type::block_log2(N));
-
-      int num_mp = Device::NumMultiprocessors(Device::GetId());
-#if defined(MFEM_USE_CUDA)
-      // good value of mp_sat found experimentally on Lassen
-      constexpr int mp_sat = 8;
-#elif defined(MFEM_USE_HIP)
-      // good value of mp_sat found experimentally on Tuolumne
-      constexpr int mp_sat = 4;
-#else
-      num_mp = 1;
-      constexpr int mp_sat = 1;
-#endif
-      // determine how many items each thread should sum during the serial
-      // portion
-      int nblocks = std::min(mp_sat * num_mp, (N + block_size - 1) / block_size);
-      int items_per_thread =
-         (N + block_size * nblocks - 1) / (block_size * nblocks);
-
-      red_type red{nullptr, std::forward<B>(body), reducer, N, items_per_thread};
-      // allocate res to fit block_size entries
-      auto mt = workspace.GetMemory().GetMemoryType();
-      if (mt != MemoryType::HOST_PINNED && mt != MemoryType::MANAGED)
-      {
-         mt = MemoryType::HOST_PINNED;
-      }
-      workspace.SetSize(nblocks, mt);
-      auto work = workspace.HostWrite();
-      red.work = work;
-      forall_2D(nblocks, block_size, 1, std::move(red));
-      // wait for results
-      MFEM_DEVICE_SYNC;
-      for (int i = 0; i < nblocks; ++i)
-      {
-         reducer.Join(res, work[i]);
-      }
-      return;
-   }
-#endif
-
-   for (int i = 0; i < N; ++i)
-   {
-      body(i, res);
-   }
-}
-
 } // namespace mfem

 #endif // MFEM_FORALL_HPP
diff --git a/general/reducers.hpp b/general/reducers.hpp
index 2b77fcbf1a..dde3bd4e5d 100644
--- a/general/reducers.hpp
+++ b/general/reducers.hpp
@@ -12,11 +12,10 @@
 #ifndef MFEM_REDUCERS_HPP
 #define MFEM_REDUCERS_HPP

+#include "array.hpp"
 #include "forall.hpp"

-#include <climits>
 #include <cmath>
-#include <cstdint>
 #include <limits>
 #include <type_traits>

@@ -439,6 +438,160 @@ template <class I> struct ArgMinMaxReducer<double, I>
    }
 };

-} // namespace mfem
+namespace internal
+{
+
+/**
+ @brief Device portion of a reduction over a 1D sequence [0, N)
+ @tparam B Reduction body. Must be callable with the signature void(int i, value_type&
+ v), where i is the index to evaluate and v is the value to update.
+ @tparam R Reducer capable of combining values of type value_type. See reducers.hpp for
+ pre-defined reducers.
+ */
+template<class B, class R> struct reduction_kernel
+{
+   /// value type body and reducer operate on.
+   using value_type = typename R::value_type;
+   /// workspace for the intermediate reduction results
+   mutable value_type *work;
+   B body;
+   R reducer;
+   /// Length of sequence to reduce over.
+   int N;
+   /// How many items is each thread responsible for during the serial phase
+   int items_per_thread;
+
+   constexpr static MFEM_HOST_DEVICE int max_blocksize() { return 256; }
+
+   /// helper for computing the reduction block size
+   static int block_log2(unsigned N)
+   {
+#if defined(__GNUC__) or defined(__clang__)
+      return N ? (sizeof(unsigned) * 8 - __builtin_clz(N)) : 0;
+#elif defined(_MSC_VER)
+      return sizeof(unsigned) * 8 - __lzclz(N);
+#else
+      int res = 0;
+      while (N)
+      {
+         N >>= 1;
+         ++res;
+      }
+      return res;
+#endif
+   }

+   MFEM_HOST_DEVICE void operator()(int work_idx) const
+   {
+      MFEM_SHARED value_type buffer[max_blocksize()];
+      reducer.SetInitialValue(buffer[MFEM_THREAD_ID(x)]);
+      // serial part
+      for (int idx = 0; idx < items_per_thread; ++idx)
+      {
+         int i = MFEM_THREAD_ID(x) +
+                 (idx + work_idx * items_per_thread) * MFEM_THREAD_SIZE(x);
+         if (i < N)
+         {
+            body(i, buffer[MFEM_THREAD_ID(x)]);
+         }
+         else
+         {
+            break;
+         }
+      }
+      // binary tree reduction
+      for (int i = (MFEM_THREAD_SIZE(x) >> 1); i > 0; i >>= 1)
+      {
+         MFEM_SYNC_THREAD;
+         if (MFEM_THREAD_ID(x) < i)
+         {
+            reducer.Join(buffer[MFEM_THREAD_ID(x)], buffer[MFEM_THREAD_ID(x) + i]);
+         }
+      }
+      if (MFEM_THREAD_ID(x) == 0)
+      {
+         work[work_idx] = buffer[0];
+      }
+   }
+};
+}
+
+/**
+ @brief Performs a 1D reduction on the range [0,N).
+ @a res initial value and where the result will be written.
+ @a body reduction function body.
+ @a reducer helper for joining two reduced values.
+ @a use_dev true to perform the reduction on the device, if possible.
+ @a workspace temporary workspace used for device reductions. May be resized to
+ a larger capacity as needed. Preferably should have MemoryType::MANAGED or
+ MemoryType::HOST_PINNED. TODO: replace with internal temporary workspace
+ vectors once that's added to the memory manager.
+ @tparam T value_type to operate on
+ */
+template <class T, class B, class R>
+void reduce(int N, T &res, B &&body, const R &reducer, bool use_dev,
+            Array<T> &workspace)
+{
+   if (N == 0)
+   {
+      return;
+   }
+
+#if defined(MFEM_USE_HIP) || defined(MFEM_USE_CUDA)
+   if (use_dev &&
+       mfem::Device::Allows(Backend::CUDA | Backend::HIP | Backend::RAJA_CUDA |
+                            Backend::RAJA_HIP))
+   {
+      using red_type = internal::reduction_kernel<typename std::decay<B>::type,
+            typename std::decay<R>::type>;
+      // max block size is 256, but can be smaller
+      int block_size = std::min<int>(red_type::max_blocksize(),
+                                     1ll << red_type::block_log2(N));
+
+      int num_mp = Device::NumMultiprocessors(Device::GetId());
+#if defined(MFEM_USE_CUDA)
+      // good value of mp_sat found experimentally on Lassen
+      constexpr int mp_sat = 8;
+#elif defined(MFEM_USE_HIP)
+      // good value of mp_sat found experimentally on Tuolumne
+      constexpr int mp_sat = 4;
+#else
+      num_mp = 1;
+      constexpr int mp_sat = 1;
 #endif
+      // determine how many items each thread should sum during the serial
+      // portion
+      int nblocks = std::min(mp_sat * num_mp, (N + block_size - 1) / block_size);
+      int items_per_thread =
+         (N + block_size * nblocks - 1) / (block_size * nblocks);
+
+      red_type red{nullptr, std::forward<B>(body), reducer, N, items_per_thread};
+      // allocate res to fit block_size entries
+      auto mt = workspace.GetMemory().GetMemoryType();
+      if (mt != MemoryType::HOST_PINNED && mt != MemoryType::MANAGED)
+      {
+         mt = MemoryType::HOST_PINNED;
+      }
+      workspace.SetSize(nblocks, mt);
+      auto work = workspace.HostWrite();
+      red.work = work;
+      forall_2D(nblocks, block_size, 1, std::move(red));
+      // wait for results
+      MFEM_DEVICE_SYNC;
+      for (int i = 0; i < nblocks; ++i)
+      {
+         reducer.Join(res, work[i]);
+      }
+      return;
+   }
+#endif
+
+   for (int i = 0; i < N; ++i)
+   {
+      body(i, res);
+   }
+}
+
+} // namespace mfem
+
+#endif // MFEM_REDUCERS_HPP
diff --git a/linalg/vector.cpp b/linalg/vector.cpp
index 87b063c025..defdb74232 100644
--- a/linalg/vector.cpp
+++ b/linalg/vector.cpp
@@ -11,19 +11,18 @@

 // Implementation of data type vector

-#include "kernels.hpp"
-#include "vector.hpp"
 #include "../general/forall.hpp"
+#include "../general/reducers.hpp"
+#include "../general/hash.hpp"
+#include "vector.hpp"

 #ifdef MFEM_USE_OPENMP
 #include <omp.h>
 #endif

 #include <iostream>
-#include <iomanip>
 #include <cmath>
 #include <ctime>
-#include <limits>

 namespace mfem
 {
@@ -207,7 +206,7 @@ Vector &Vector::operator=(const Vector &v)
    UseDevice(v.UseDevice());
 #else
    SetSize(v.Size());
-   bool vuse = v.UseDevice();
+   const bool vuse = v.UseDevice();
    const bool use_dev = UseDevice() || vuse;
    v.UseDevice(use_dev);
    // keep 'data' where it is, unless 'use_dev' is true
@@ -249,8 +248,8 @@ Vector &Vector::operator*=(const Vector &v)

    const bool use_dev = UseDevice() || v.UseDevice();
    const int N = size;
+   const auto x = v.Read(use_dev);
    auto y = ReadWrite(use_dev);
-   auto x = v.Read(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] *= x[i]; });
    return *this;
 }
@@ -271,8 +270,8 @@ Vector &Vector::operator/=(const Vector &v)

    const bool use_dev = UseDevice() || v.UseDevice();
    const int N = size;
+   const auto x = v.Read(use_dev);
    auto y = ReadWrite(use_dev);
-   auto x = v.Read(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] /= x[i]; });
    return *this;
 }
@@ -292,8 +291,8 @@ Vector &Vector::operator-=(const Vector &v)

    const bool use_dev = UseDevice() || v.UseDevice();
    const int N = size;
+   const auto x = v.Read(use_dev);
    auto y = ReadWrite(use_dev);
-   auto x = v.Read(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] -= x[i]; });
    return *this;
 }
@@ -313,8 +312,8 @@ Vector &Vector::operator+=(const Vector &v)

    const bool use_dev = UseDevice() || v.UseDevice();
    const int N = size;
+   const auto x = v.Read(use_dev);
    auto y = ReadWrite(use_dev);
-   auto x = v.Read(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] += x[i]; });
    return *this;
 }
@@ -327,8 +326,8 @@ Vector &Vector::Add(const real_t a, const Vector &Va)
    {
       const int N = size;
       const bool use_dev = UseDevice() || Va.UseDevice();
+      const auto x = Va.Read(use_dev);
       auto y = ReadWrite(use_dev);
-      auto x = Va.Read(use_dev);
       mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] += a * x[i]; });
    }
    return *this;
@@ -340,7 +339,7 @@ Vector &Vector::Set(const real_t a, const Vector &Va)

    const bool use_dev = UseDevice() || Va.UseDevice();
    const int N = size;
-   auto x = Va.Read(use_dev);
+   const auto x = Va.Read(use_dev);
    auto y = Write(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] = a * x[i]; });
    return *this;
@@ -352,9 +351,9 @@ void Vector::SetVector(const Vector &v, int offset)

    const bool use_dev = UseDevice() || v.UseDevice();
    const int vs = v.Size();
-   const real_t *vp = v.Read(use_dev);
+   const auto vp = v.Read(use_dev);
    // Use read+write access for *this - we only modify some of its entries
-   real_t *p = ReadWrite(use_dev) + offset;
+   auto p = ReadWrite(use_dev) + offset;
    mfem::forall_switch(use_dev, vs, [=] MFEM_HOST_DEVICE (int i) { p[i] = vp[i]; });
 }

@@ -364,8 +363,8 @@ void Vector::AddSubVector(const Vector &v, int offset)

    const bool use_dev = UseDevice() || v.UseDevice();
    const int vs = v.Size();
-   const real_t *vp = v.Read(use_dev);
-   real_t *p = ReadWrite(use_dev) + offset;
+   const auto vp = v.Read(use_dev);
+   auto p = ReadWrite(use_dev) + offset;
    mfem::forall_switch(use_dev, vs, [=] MFEM_HOST_DEVICE (int i) { p[i] += vp[i]; });
 }

@@ -394,8 +393,8 @@ void add(const Vector &v1, const Vector &v2, Vector &v)
    const bool use_dev = v1.UseDevice() || v2.UseDevice() || v.UseDevice();
    const int N = v.size;
    // Note: get read access first, in case v is the same as v1/v2.
-   auto x1 = v1.Read(use_dev);
-   auto x2 = v2.Read(use_dev);
+   const auto x1 = v1.Read(use_dev);
+   const auto x2 = v2.Read(use_dev);
    auto y = v.Write(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { y[i] = x1[i] + x2[i]; });
 #else
@@ -426,8 +425,8 @@ void add(const Vector &v1, real_t alpha, const Vector &v2, Vector &v)
       const bool use_dev = v1.UseDevice() || v2.UseDevice() || v.UseDevice();
       const int N = v.size;
       // Note: get read access first, in case v is the same as v1/v2.
-      auto d_x = v1.Read(use_dev);
-      auto d_y = v2.Read(use_dev);
+      const auto d_x = v1.Read(use_dev);
+      const auto d_y = v2.Read(use_dev);
       auto d_z = v.Write(use_dev);
       mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i)
       {
@@ -465,8 +464,8 @@ void add(const real_t a, const Vector &x, const Vector &y, Vector &z)
       const bool use_dev = x.UseDevice() || y.UseDevice() || z.UseDevice();
       const int N = x.size;
       // Note: get read access first, in case z is the same as x/y.
-      auto xd = x.Read(use_dev);
-      auto yd = y.Read(use_dev);
+      const auto xd = x.Read(use_dev);
+      const auto yd = y.Read(use_dev);
       auto zd = z.Write(use_dev);
       mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i)
       {
@@ -520,8 +519,8 @@ void add(const real_t a, const Vector &x,
       const bool use_dev = x.UseDevice() || y.UseDevice() || z.UseDevice();
       const int N = x.size;
       // Note: get read access first, in case z is the same as x/y.
-      auto xd = x.Read(use_dev);
-      auto yd = y.Read(use_dev);
+      const auto xd = x.Read(use_dev);
+      const auto yd = y.Read(use_dev);
       auto zd = z.Write(use_dev);
       mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i)
       {
@@ -550,8 +549,8 @@ void subtract(const Vector &x, const Vector &y, Vector &z)
    const bool use_dev = x.UseDevice() || y.UseDevice() || z.UseDevice();
    const int N = x.size;
    // Note: get read access first, in case z is the same as x/y.
-   auto xd = x.Read(use_dev);
-   auto yd = y.Read(use_dev);
+   const auto xd = x.Read(use_dev);
+   const auto yd = y.Read(use_dev);
    auto zd = z.Write(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i)
    {
@@ -589,8 +588,8 @@ void subtract(const real_t a, const Vector &x, const Vector &y, Vector &z)
       const bool use_dev = x.UseDevice() || y.UseDevice() || z.UseDevice();
       const int N = x.size;
       // Note: get read access first, in case z is the same as x/y.
-      auto xd = x.Read(use_dev);
-      auto yd = y.Read(use_dev);
+      const auto xd = x.Read(use_dev);
+      const auto yd = y.Read(use_dev);
       auto zd = z.Write(use_dev);
       mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i)
       {
@@ -631,8 +630,8 @@ void Vector::median(const Vector &lo, const Vector &hi)
    const bool use_dev = UseDevice() || lo.UseDevice() || hi.UseDevice();
    const int N = size;
    // Note: get read access first, in case *this is the same as lo/hi.
-   auto l = lo.Read(use_dev);
-   auto h = hi.Read(use_dev);
+   const auto l = lo.Read(use_dev);
+   const auto h = hi.Read(use_dev);
    auto m = Write(use_dev);
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i)
    {
@@ -652,9 +651,9 @@ void Vector::GetSubVector(const Array<int> &dofs, Vector &elemvect) const
    const int n = dofs.Size();
    elemvect.SetSize(n);
    const bool use_dev = dofs.UseDevice() || elemvect.UseDevice();
+   const auto d_X = Read(use_dev);
+   const auto d_dofs = dofs.Read(use_dev);
    auto d_y = elemvect.Write(use_dev);
-   auto d_X = Read(use_dev);
-   auto d_dofs = dofs.Read(use_dev);
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i)
    {
       const int dof_i = d_dofs[i];
@@ -664,7 +663,7 @@ void Vector::GetSubVector(const Array<int> &dofs, Vector &elemvect) const

 void Vector::GetSubVector(const Array<int> &dofs, real_t *elem_data) const
 {
-   data.Read(MemoryClass::HOST, size);
+   HostRead();
    const int n = dofs.Size();
    for (int i = 0; i < n; i++)
    {
@@ -679,7 +678,7 @@ void Vector::SetSubVector(const Array<int> &dofs, const real_t value)
    const int n = dofs.Size();
    // Use read+write access for *this - we only modify some of its entries
    auto d_X = ReadWrite(use_dev);
-   auto d_dofs = dofs.Read(use_dev);
+   const auto d_dofs = dofs.Read(use_dev);
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i)
    {
       const int j = d_dofs[i];
@@ -721,8 +720,8 @@ void Vector::SetSubVector(const Array<int> &dofs, const Vector &elemvect)
    const int n = dofs.Size();
    // Use read+write access for X - we only modify some of its entries
    auto d_X = ReadWrite(use_dev);
-   auto d_y = elemvect.Read(use_dev);
-   auto d_dofs = dofs.Read(use_dev);
+   const auto d_y = elemvect.Read(use_dev);
+   const auto d_dofs = dofs.Read(use_dev);
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i)
    {
       const int dof_i = d_dofs[i];
@@ -740,7 +739,7 @@ void Vector::SetSubVector(const Array<int> &dofs, const Vector &elemvect)
 void Vector::SetSubVector(const Array<int> &dofs, real_t *elem_data)
 {
    // Use read+write access because we overwrite only part of the data.
-   data.ReadWrite(MemoryClass::HOST, size);
+   HostReadWrite();
    const int n = dofs.Size();
    for (int i = 0; i < n; i++)
    {
@@ -764,9 +763,9 @@ void Vector::AddElementVector(const Array<int> &dofs, const Vector &elemvect)

    const bool use_dev = dofs.UseDevice() || elemvect.UseDevice();
    const int n = dofs.Size();
-   auto d_y = elemvect.Read(use_dev);
+   const auto d_y = elemvect.Read(use_dev);
+   const auto d_dofs = dofs.Read(use_dev);
    auto d_X = ReadWrite(use_dev);
-   auto d_dofs = dofs.Read(use_dev);
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i)
    {
       const int j = d_dofs[i];
@@ -783,7 +782,7 @@ void Vector::AddElementVector(const Array<int> &dofs, const Vector &elemvect)

 void Vector::AddElementVector(const Array<int> &dofs, real_t *elem_data)
 {
-   data.ReadWrite(MemoryClass::HOST, size);
+   HostReadWrite();
    const int n = dofs.Size();
    for (int i = 0; i < n; i++)
    {
@@ -808,9 +807,9 @@ void Vector::AddElementVector(const Array<int> &dofs, const real_t a,

    const bool use_dev = dofs.UseDevice() || elemvect.UseDevice();
    const int n = dofs.Size();
+   const auto d_x = elemvect.Read(use_dev);
+   const auto d_dofs = dofs.Read(use_dev);
    auto d_y = ReadWrite(use_dev);
-   auto d_x = elemvect.Read(use_dev);
-   auto d_dofs = dofs.Read(use_dev);
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i)
    {
       const int j = d_dofs[i];
@@ -835,7 +834,7 @@ void Vector::SetSubVectorComplement(const Array<int> &dofs, const real_t val)
                     Device::GetHostMemoryType());
    auto d_data = ReadWrite(use_dev);
    auto d_dofs_vals = dofs_vals.Write(use_dev);
-   auto d_dofs = dofs.Read(use_dev);
+   const auto d_dofs = dofs.Read(use_dev);
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i) { d_dofs_vals[i] = d_data[d_dofs[i]]; });
    mfem::forall_switch(use_dev, N, [=] MFEM_HOST_DEVICE (int i) { d_data[i] = val; });
    mfem::forall_switch(use_dev, n, [=] MFEM_HOST_DEVICE (int i) { d_data[d_dofs[i]] = d_dofs_vals[i]; });
@@ -844,7 +843,7 @@ void Vector::SetSubVectorComplement(const Array<int> &dofs, const real_t val)
 void Vector::Print(std::ostream &os, int width) const
 {
    if (!size) { return; }
-   data.Read(MemoryClass::HOST, size);
+   HostRead();
    for (int i = 0; 1; )
    {
       os << ZeroSubnormal(data[i]);
@@ -870,7 +869,7 @@ void Vector::Print(adios2stream &os,
                    const std::string& variable_name) const
 {
    if (!size) { return; }
-   data.Read(MemoryClass::HOST, size);
+   HostRead();
    os.engine.Put(variable_name, &data[0] );
 }
 #endif
@@ -928,10 +927,7 @@ void Vector::PrintHash(std::ostream &os) const

 void Vector::Randomize(int seed)
 {
-   if (seed == 0)
-   {
-      seed = (int)time(0);
-   }
+   if (seed == 0) { seed = (int)time(0); }

    srand((unsigned)seed);

@@ -947,20 +943,15 @@ real_t Vector::Norml2() const
    // Scale entries of Vector on the fly, using algorithms from
    // std::hypot() and LAPACK's drm2. This scaling ensures that the
    // argument of each call to std::pow is <= 1 to avoid overflow.
-   if (size == 0)
-   {
-      return 0.0;
-   }
+   if (size == 0) { return 0.0; }

-   auto m_data = Read(UseDevice());
+   const auto m_data = Read(UseDevice());
    using value_type = DevicePair<real_t, real_t>;
    value_type res;
    res.first = 0;
    res.second = 0;
    // first compute sum (|m_data|/scale)^2
-   reduce(
-      size, res,
-      [=] MFEM_HOST_DEVICE(int i, value_type &r)
+   reduce(size, res, [=] MFEM_HOST_DEVICE(int i, value_type &r)
    {
       real_t n = fabs(m_data[i]);
       if (n > 0)
@@ -987,11 +978,12 @@ real_t Vector::Normlinf() const
 {
    if (size == 0) { return 0; }

-   auto m_data = Read(UseDevice());
    real_t res = 0;
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r = fmax(r, fabs(m_data[i])); },
+   const auto m_data = Read(UseDevice());
+   reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
+   {
+      r = fmax(r, fabs(m_data[i]));
+   },
    MaxReducer<real_t> {}, UseDevice(), vector_workspace());
    return res;
 }
@@ -1000,11 +992,12 @@ real_t Vector::Norml1() const
 {
    if (size == 0) { return 0.0; }

-   auto m_data = Read(UseDevice());
    real_t res = 0;
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r += fabs(m_data[i]); },
+   const auto m_data = Read(UseDevice());
+   reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
+   {
+      r += fabs(m_data[i]);
+   },
    SumReducer<real_t> {}, UseDevice(), vector_workspace());
    return res;
 }
@@ -1013,33 +1006,24 @@ real_t Vector::Normlp(real_t p) const
 {
    MFEM_ASSERT(p > 0.0, "Vector::Normlp");

-   if (p == 1.0)
-   {
-      return Norml1();
-   }
-   if (p == 2.0)
-   {
-      return Norml2();
-   }
+   if (p == 1.0) { return Norml1(); }
+
+   if (p == 2.0) { return Norml2(); }
+
    if (p < infinity())
    {
       // Scale entries of Vector on the fly, using algorithms from
       // std::hypot() and LAPACK's drm2. This scaling ensures that the
       // argument of each call to std::pow is <= 1 to avoid overflow.
-      if (size == 0)
-      {
-         return 0.0;
-      }
+      if (size == 0) { return 0.0; }

-      auto m_data = Read(UseDevice());
       using value_type = DevicePair<real_t, real_t>;
       value_type res;
       res.first = 0;
       res.second = 0;
+      const auto m_data = Read(UseDevice());
       // first compute sum (|m_data|/scale)^p
-      reduce(
-         size, res,
-         [=] MFEM_HOST_DEVICE(int i, value_type &r)
+      reduce(size, res, [=] MFEM_HOST_DEVICE(int i, value_type &r)
       {
          real_t n = fabs(m_data[i]);
          if (n > 0)
@@ -1068,163 +1052,182 @@ real_t Vector::Normlp(real_t p) const
 real_t Vector::operator*(const Vector &v) const
 {
    MFEM_ASSERT(size == v.size, "incompatible Vectors!");
+
    if (size == 0) { return 0.0; }

    const bool use_dev = UseDevice() || v.UseDevice();
+   const auto m_data = Read(use_dev), v_data = v.Read(use_dev);

-   auto m_data = Read(use_dev);
-   auto v_data = v.Read(use_dev);
+   // If OCCA is enabled, it handles all selected backends
+#ifdef MFEM_USE_OCCA
+   if (use_dev && DeviceCanUseOcca())
+   {
+      return occa::linalg::dot<real_t, real_t, real_t>(
+                OccaMemoryRead(data, size), OccaMemoryRead(v.data, size));
+   }
+#endif

-   if (use_dev)
+   const auto compute_dot = [&]()
    {
-      // special path for OCCA and OpenMP
-#ifdef MFEM_USE_OCCA
-      if (DeviceCanUseOcca())
+      real_t res = 0;
+      reduce(size, res, [=] MFEM_HOST_DEVICE (int i, real_t &r)
       {
-         return occa::linalg::dot<real_t, real_t, real_t>(
-                   OccaMemoryRead(data, size), OccaMemoryRead(v.data, size));
-      }
-#endif
+         r += m_data[i] * v_data[i];
+      },
+      SumReducer<real_t> {}, use_dev, vector_workspace());
+      return res;
+   };

+   // Device backends have top priority
+   if (Device::Allows(Backend::DEVICE_MASK)) { return compute_dot(); }
+
+   // Special path for OpenMP
 #ifdef MFEM_USE_OPENMP
-      if (Device::Allows(Backend::OMP_MASK))
-      {
+   if (use_dev && Device::Allows(Backend::OMP_MASK))
+   {
+      // By default, use a deterministic way of computing the dot product
 #define MFEM_USE_OPENMP_DETERMINISTIC_DOT
 #ifdef MFEM_USE_OPENMP_DETERMINISTIC_DOT
-         // By default, use a deterministic way of computing the dot product
-         static Vector th_dot;
-         #pragma omp parallel
+      static Vector th_dot;
+      #pragma omp parallel
+      {
+         const int nt = omp_get_num_threads();
+         #pragma omp master
+         th_dot.SetSize(nt);
+         const int tid = omp_get_thread_num();
+         const int stride = (size + nt - 1) / nt;
+         const int start = tid * stride;
+         const int stop = std::min(start + stride, size);
+         real_t my_dot = 0.0;
+         for (int i = start; i < stop; i++)
          {
-            const int nt = omp_get_num_threads();
-            #pragma omp master
-            th_dot.SetSize(nt);
-            const int tid = omp_get_thread_num();
-            const int stride = (size + nt - 1) / nt;
-            const int start = tid * stride;
-            const int stop = std::min(start + stride, size);
-            real_t my_dot = 0.0;
-            for (int i = start; i < stop; i++)
-            {
-               my_dot += m_data[i] * v_data[i];
-            }
-            #pragma omp barrier
-            th_dot(tid) = my_dot;
+            my_dot += m_data[i] * v_data[i];
          }
-         return th_dot.Sum();
+         #pragma omp barrier
+         th_dot(tid) = my_dot;
+      }
+      return th_dot.Sum();
 #else
-         // The standard way of computing the dot product is non-deterministic
-         real_t prod = 0.0;
-         #pragma omp parallel for reduction(+ : prod)
-         for (int i = 0; i < size; i++)
-         {
-            prod += m_data[i] * v_data[i];
-         }
-         return prod;
-#endif // MFEM_USE_OPENMP_DETERMINISTIC_DOT
+      // The standard way of computing the dot product is non-deterministic
+      real_t prod = 0.0;
+      #pragma omp parallel for reduction(+ : prod)
+      for (int i = 0; i < size; i++)
+      {
+         prod += m_data[i] * v_data[i];
       }
-#endif // MFEM_USE_OPENMP
+      return prod;
+#endif // MFEM_USE_OPENMP_DETERMINISTIC_DOT
    }
+#endif // MFEM_USE_OPENMP

-   // normal path for everything else (cuda, hip, debug, cpu)
-   real_t res = 0;
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r += m_data[i] * v_data[i]; },
-   SumReducer<real_t> {}, use_dev, vector_workspace());
-   return res;
+   // All other CPU backends
+   return compute_dot();
 }

 real_t Vector::Min() const
 {
    if (size == 0) { return infinity(); }

-   const bool use_dev = UseDevice();
-   auto m_data = Read(use_dev);
+   const auto use_dev = UseDevice();
+   const auto m_data = Read(use_dev);

-   if (use_dev)
+#ifdef MFEM_USE_OCCA
+   if (use_dev && DeviceCanUseOcca())
    {
-      // special case for OCCA and OpenMP
+      return occa::linalg::min<real_t,real_t>(OccaMemoryRead(data, size));
+   }
+#endif

-#ifdef MFEM_USE_OCCA
-      if (DeviceCanUseOcca())
+   const auto compute_min = [&]()
+   {
+      real_t res = infinity();
+      reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
       {
-         return occa::linalg::min<real_t,real_t>(OccaMemoryRead(data, size));
-      }
-#endif
+         r = fmin(r, m_data[i]);
+      },
+      MinReducer<real_t> {}, use_dev, vector_workspace());
+      return res;
+   };

+   // Device backends have top priority
+   if (Device::Allows(Backend::DEVICE_MASK)) { return compute_min(); }
+
+   // Special path for OpenMP
 #ifdef MFEM_USE_OPENMP
-      if (Device::Allows(Backend::OMP_MASK))
+   if (use_dev && Device::Allows(Backend::OMP_MASK))
+   {
+      real_t minimum = m_data[0];
+      #pragma omp parallel for reduction(min:minimum)
+      for (int i = 0; i < size; i++)
       {
-         real_t minimum = m_data[0];
-         #pragma omp parallel for reduction(min:minimum)
-         for (int i = 0; i < size; i++)
-         {
-            minimum = std::min(minimum, m_data[i]);
-         }
-         return minimum;
+         minimum = std::min(minimum, m_data[i]);
       }
-#endif
+      return minimum;
    }
+#endif

-   // normal path for everything else (cuda, hip, debug, cpu)
-   real_t res = infinity();
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r = fmin(r, m_data[i]); },
-   MinReducer<real_t> {}, use_dev, vector_workspace());
-   return res;
+   // All other CPU backends
+   return compute_min();
 }

 real_t Vector::Max() const
 {
    if (size == 0) { return -infinity(); }

-   const bool use_dev = UseDevice();
-   auto m_data = Read(use_dev);
+   const auto use_dev = UseDevice();
+   const auto m_data = Read(use_dev);

-   if (use_dev)
-   {
-      // special cases where OCCA or OenMP are used
 #ifdef MFEM_USE_OCCA
-      if (DeviceCanUseOcca())
-      {
-         return occa::linalg::max<real_t, real_t>(OccaMemoryRead(data, size));
-      }
+   if (use_dev && DeviceCanUseOcca())
+   {
+      return occa::linalg::max<real_t, real_t>(OccaMemoryRead(data, size));
+   }
 #endif

+   const auto compute_max = [&]()
+   {
+      real_t res = -infinity();
+      reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
+      {
+         r = fmax(r, m_data[i]);
+      },
+      MaxReducer<real_t> {}, use_dev, vector_workspace());
+      return res;
+   };
+
+   // Device backends have top priority
+   if (Device::Allows(Backend::DEVICE_MASK)) { return compute_max(); }
+
+   // Special path for OpenMP
 #ifdef MFEM_USE_OPENMP
-      if (Device::Allows(Backend::OMP_MASK))
+   if (use_dev && Device::Allows(Backend::OMP_MASK))
+   {
+      real_t maximum = m_data[0];
+      #pragma omp parallel for reduction(max : maximum)
+      for (int i = 0; i < size; i++)
       {
-         real_t maximum = m_data[0];
-         #pragma omp parallel for reduction(max : maximum)
-         for (int i = 0; i < size; i++)
-         {
-            maximum = fmax(maximum, m_data[i]);
-         }
-         return maximum;
+         maximum = fmax(maximum, m_data[i]);
       }
-#endif
+      return maximum;
    }
+#endif

-   // normal path for everything else (cuda, hip, debug, cpu)
-   real_t res = -infinity();
-   reduce(
-      size, res,
-   [=] MFEM_HOST_DEVICE(int i, real_t &r) { r = fmax(r, m_data[i]); },
-   MaxReducer<real_t> {}, use_dev, vector_workspace());
-   return res;
+   // All other CPU backends
+   return compute_max();
 }

 real_t Vector::Sum() const
 {
    if (size == 0) { return 0.0; }

-   auto m_data = Read(UseDevice());
    real_t res = 0;
-   reduce(
-   size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r) { r += m_data[i]; },
+   const auto m_data = Read(UseDevice());
+   reduce(size, res, [=] MFEM_HOST_DEVICE(int i, real_t &r)
+   {
+      r += m_data[i];
+   },
    SumReducer<real_t> {}, UseDevice(), vector_workspace());
    return res;
 }

-}
+} // namespace mfem
diff --git a/tests/unit/general/test_reduction.cpp b/tests/unit/general/test_reduction.cpp
index 13b9077381..ad12cdb62d 100644
--- a/tests/unit/general/test_reduction.cpp
+++ b/tests/unit/general/test_reduction.cpp
@@ -9,15 +9,14 @@
 // terms of the BSD-3 license. We welcome feedback and contributions, see file
 // CONTRIBUTING.md for details.

-#include "mfem.hpp"
-
-// must be included after mfem.hpp
-#include "general/forall.hpp"
+#include <algorithm>
+#include <limits>

+#include "mfem.hpp"
 #include "unit_tests.hpp"

-#include <algorithm>
-#include <limits>
+// must be included after mfem.hpp
+#include "general/reducers.hpp"

 using namespace mfem;
